{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test a classifier's generalizability, or its ability to provide accurate predictions on data it wasn't trained on, we use cross-validation techniques. Cross-validation involves splitting historical data into:\n",
    "\n",
    "    a training set -- which we use to train the classifer,\n",
    "    a test set -- which we use to evaluate the classifier's effectiveness using various measures.\n",
    "\n",
    "Cross-validation is an important step that should be utilized after training any kind of machine learning model. In this mission, we'll focus on using cross-validation for evaluating a binary classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        gpa         gre  actual_label\n",
      "0  3.177277  594.102992             0\n",
      "1  3.412655  631.528607             0\n",
      "2  2.728097  553.714399             0\n",
      "3  3.093559  551.089985             0\n",
      "4  3.141923  537.184894             0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "admissions = pd.read_csv(\"admissions.csv\")\n",
    "admissions[\"actual_label\"] = admissions[\"admit\"]\n",
    "admissions = admissions.drop(\"admit\", axis=1)\n",
    "\n",
    "print(admissions.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy\n",
    "\n",
    "Now that we've split up the dataset into a training and a test set, we can:\n",
    "\n",
    "    train a logistic regression model on just the training set,\n",
    "    use the model to predict labels for the test set,\n",
    "    evaluate the accuracy of the predicted labels for the test set.\n",
    "\n",
    "Recall that accuracy helps us answer the question:\n",
    "\n",
    "    What fraction of the predictions were correct (actual label matched predicted label)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.635658914729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kknagara\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(8)\n",
    "\n",
    "shuffled_index = np.random.permutation(admissions.index) #shuffle the index of the dataframe\n",
    "shuffled_admissions = admissions.loc[shuffled_index] # new dataframe with shuffled index\n",
    "train = shuffled_admissions.iloc[0:515] # first 80% rows as training data\n",
    "test = shuffled_admissions.iloc[515:len(shuffled_admissions)] # rest 20% as testing data\n",
    "\n",
    "lr=LogisticRegression()\n",
    "lr.fit(train[[\"gpa\"]],train[\"actual_label\"]) #fitting on the training set\n",
    "labels=lr.predict(test[[\"gpa\"]])             #predicting on the testitng set\n",
    "\n",
    "test[\"predicted_label\"] = labels             # creating a new column for the predicted values\n",
    "matches = test[\"predicted_label\"] == test[\"actual_label\"] # renaming the admit column to actual predicted values\n",
    "correct_predictions = test[matches]\n",
    "accuracy = float(len(correct_predictions)) / float(len(test))\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    Sensitivity helps us answer the question:\n",
    "        How effective is this model at identifying positive outcomes?\n",
    "        Of all of the students that should have been admitted (True Positives + False Negatives), how many did the model correctly admit (True Positives)?\n",
    "    Specificity helps us answer the question:\n",
    "        How effective is this model at identifying negative outcomes?\n",
    "        Of all of the applicants who should have been rejected (False Positives + True Negatives), what proportion were correctly rejected (just True Negatives).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0833333333333\n",
      "0.962962962963\n"
     ]
    }
   ],
   "source": [
    "true_positive_filter = (test[\"predicted_label\"] == 1) & (test[\"actual_label\"] == 1)\n",
    "true_positives = len(test[true_positive_filter])\n",
    "false_negative_filter = (test[\"predicted_label\"] == 0) & (test[\"actual_label\"] == 1)\n",
    "false_negatives = len(test[false_negative_filter])\n",
    "\n",
    "sensitivity = float(true_positives) / float(true_positives + false_negatives)\n",
    "print(sensitivity)\n",
    "\n",
    "false_positive_filter = (test[\"predicted_label\"] == 1) & (test[\"actual_label\"] == 0)\n",
    "false_positives = len(test[false_positive_filter])\n",
    "true_negative_filter=(test[\"predicted_label\"]==0) & (test[\"actual_label\"]==0)\n",
    "true_negatives = len(test[true_negative_filter])\n",
    "\n",
    "specificity = float(true_negatives) / float(false_positives + true_negatives)\n",
    "print(specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " False positive rate\n",
    "\n",
    "It turns out that our test set achieved a sensitivity value of 8.3, compared to a sensitivity value of 12.7% from the previous mission, and a specificity value of 96.3%, which matches the specificity value of 96.3% from the previous mission. We have a little more evidence now that our logistic regression model is able to generalize to new data.\n",
    "These 2 rates describe how well the model accepts the right students and how poorly it rejects the wrong one:\n",
    "\n",
    "    True Positive Rate (TPR): The proportion of students that were admitted that should have been admitted.\n",
    "    False Positive Rate(FPR): The proportion of students that were accepted that should have been rejected.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC curve\n",
    "\n",
    "We can vary the discrimination threshold and calculate the TPR and FPR for each value. This is called an ROC curve, which stands for receiver operator curve, and it allows us to understand a classification model's performance as the discrimination threshold is varied. To calculate the TPR and FPR values at each discrimination threshold, we can use the scikit-learn roc_curve function. This function will calculate the false positive rate and true positive rate for varying discrimination thresholds until both reach 0%.\n",
    "\n",
    "This function takes 2 required parameters:\n",
    "\n",
    "    y_true: list of the true labels for the observations,\n",
    "    y_score: list of the model's probability scores for those observations.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgsAAAFkCAYAAACuFXjcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRYYFSZJUZFiQJElFhgVJklT0/wECKVREPouMPwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xbf5bf28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "probabilities=lr.predict_proba(test[[\"gpa\"]])\n",
    "fpr,tpr,thresholds=roc_curve(test[\"actual_label\"],probabilities[:,1])\n",
    "plt.plot(fpr,tpr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Area under curve (AUC)\n",
    "The AUC describes the probability that the classifier will rank a random positive observation higher than a random negative observation. Since randomly guessing converges to a probability of 0.5, the higher the AUC the more accurate the model seems to be.\n",
    "\n",
    "To calculate the AUC, we can use the scikit-learn function roc_auc_score, which takes the same parameters as the roc_curve function and returns a single float value corresponding to the AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.577932098765\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "auc_score=roc_auc_score(test[\"actual_label\"],probabilities[:,1])\n",
    "print(auc_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
